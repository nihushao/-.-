{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 常规赛：中文新闻文本标题分类Baseline(PaddleNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 一.方案介绍\n",
    "\n",
    "\n",
    "## 1. 思路：\n",
    "\n",
    "本代码主要是新手学习，主要基于baseline，进行调参等训练方法的改动\n",
    "代码主体参考飞桨比赛达人炼丹师233提供的baseline：https://aistudio.baidu.com/aistudio/projectdetail/2311230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二.数据读取与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data/data103654\n"
     ]
    }
   ],
   "source": [
    "# 进入比赛数据集存放目录\r\n",
    "%cd /home/aistudio/data/data103654/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用pandas读取数据集\r\n",
    "import pandas as pd\r\n",
    "train = pd.read_table('train.txt', sep='\\t',header=None)  # 训练集\r\n",
    "dev = pd.read_table('dev.txt', sep='\\t',header=None)      # 验证集\r\n",
    "test = pd.read_table('test.txt', sep='\\t',header=None)    # 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 添加列名便于对数据进行更好处理\r\n",
    "train.columns = [\"text_a\",'label']\r\n",
    "dev.columns = [\"text_a\",'label']\r\n",
    "test.columns = [\"text_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>网易第三季度业绩低于分析师预期</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>巴萨1年前地狱重现这次却是天堂 再赴魔鬼客场必翻盘</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>美国称支持向朝鲜提供紧急人道主义援助</td>\n",
       "      <td>时政</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>增资交银康联 交行夺参股险商首单</td>\n",
       "      <td>股票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>午盘：原材料板块领涨大盘</td>\n",
       "      <td>股票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752466</th>\n",
       "      <td>天津女排奇迹之源竟在场边 他是五冠王真正核心</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752467</th>\n",
       "      <td>北电网络专利拍卖推迟：可能分拆6部分拍卖</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752468</th>\n",
       "      <td>Spirit AeroSystems债券发行价确定</td>\n",
       "      <td>股票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752469</th>\n",
       "      <td>陆慧明必发火线：法兰克福无胜 曼联国米顺利过关</td>\n",
       "      <td>彩票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752470</th>\n",
       "      <td>首破万元 索尼46寸全新LED液晶特价促</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text_a label\n",
       "0                 网易第三季度业绩低于分析师预期    科技\n",
       "1       巴萨1年前地狱重现这次却是天堂 再赴魔鬼客场必翻盘    体育\n",
       "2              美国称支持向朝鲜提供紧急人道主义援助    时政\n",
       "3                增资交银康联 交行夺参股险商首单    股票\n",
       "4                    午盘：原材料板块领涨大盘    股票\n",
       "...                           ...   ...\n",
       "752466     天津女排奇迹之源竟在场边 他是五冠王真正核心    体育\n",
       "752467       北电网络专利拍卖推迟：可能分拆6部分拍卖    科技\n",
       "752468  Spirit AeroSystems债券发行价确定    股票\n",
       "752469    陆慧明必发火线：法兰克福无胜 曼联国米顺利过关    彩票\n",
       "752470       首破万元 索尼46寸全新LED液晶特价促    科技\n",
       "\n",
       "[752471 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练集，共752471条\r\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>网民市民集体幻想中奖后如果你中了9000万怎么办</td>\n",
       "      <td>彩票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PVC期货有望5月挂牌</td>\n",
       "      <td>财经</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>午时三刻新作《幻神录―宿命情缘》</td>\n",
       "      <td>游戏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>欧司朗LLFY网络提供一站式照明解决方案</td>\n",
       "      <td>家居</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>试探北京楼市向何方：排不完的队　涨不够的价</td>\n",
       "      <td>房产</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>王大雷看国足比赛预测比分我觉得是2-0或者3-1</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>克雷扎回归猛龙势如破竹希尔遭驱逐太阳惨败51分</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>王建宙将与台商共创4G网络商机</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>普京突访食品超市做调查不满高价猪肉(图)</td>\n",
       "      <td>时政</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>高空俯视女明星性感乳沟(组图)(7)</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text_a label\n",
       "0      网民市民集体幻想中奖后如果你中了9000万怎么办    彩票\n",
       "1                   PVC期货有望5月挂牌    财经\n",
       "2              午时三刻新作《幻神录―宿命情缘》    游戏\n",
       "3          欧司朗LLFY网络提供一站式照明解决方案    家居\n",
       "4         试探北京楼市向何方：排不完的队　涨不够的价    房产\n",
       "...                         ...   ...\n",
       "79995  王大雷看国足比赛预测比分我觉得是2-0或者3-1    体育\n",
       "79996   克雷扎回归猛龙势如破竹希尔遭驱逐太阳惨败51分    体育\n",
       "79997           王建宙将与台商共创4G网络商机    科技\n",
       "79998      普京突访食品超市做调查不满高价猪肉(图)    时政\n",
       "79999        高空俯视女明星性感乳沟(组图)(7)    时尚\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看验证集，共80000条\r\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京君太百货璀璨秋色 满100省353020元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>教育部：小学高年级将开始学习性知识</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>专业级单反相机 佳能7D单机售价9280元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>星展银行起诉内地客户 银行强硬客户无奈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>脱离中国的实际 强压人民币大幅升值只能是梦想</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83594</th>\n",
       "      <td>Razer杯DotA精英挑战赛8月震撼登场</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83595</th>\n",
       "      <td>经济数据好转吹散人民币贬值预期</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83596</th>\n",
       "      <td>抵押率抵押物双控政策 刘明康支招房产贷款</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83597</th>\n",
       "      <td>8000万像素 利图发布Aptus-II 12数码后背</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83598</th>\n",
       "      <td>教育部公布33个国家万余所正规学校名单</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83599 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text_a\n",
       "0          北京君太百货璀璨秋色 满100省353020元\n",
       "1                教育部：小学高年级将开始学习性知识\n",
       "2            专业级单反相机 佳能7D单机售价9280元\n",
       "3              星展银行起诉内地客户 银行强硬客户无奈\n",
       "4           脱离中国的实际 强压人民币大幅升值只能是梦想\n",
       "...                            ...\n",
       "83594        Razer杯DotA精英挑战赛8月震撼登场\n",
       "83595              经济数据好转吹散人民币贬值预期\n",
       "83596         抵押率抵押物双控政策 刘明康支招房产贷款\n",
       "83597  8000万像素 利图发布Aptus-II 12数码后背\n",
       "83598          教育部公布33个国家万余所正规学校名单\n",
       "\n",
       "[83599 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看测试集，共83599条\r\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 拼接训练和验证集，便于统计分析\r\n",
    "total = pd.concat([train,dev],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科技    162245\n",
       "股票    153949\n",
       "体育    130982\n",
       "娱乐     92228\n",
       "时政     62867\n",
       "社会     50541\n",
       "教育     41680\n",
       "财经     36963\n",
       "家居     32363\n",
       "游戏     24283\n",
       "房产     19922\n",
       "时尚     13335\n",
       "彩票      7598\n",
       "星座      3515\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总类别标签分布统计\r\n",
    "total['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    832471.000000\n",
       "mean         19.388112\n",
       "std           4.097139\n",
       "min           2.000000\n",
       "25%          17.000000\n",
       "50%          20.000000\n",
       "75%          23.000000\n",
       "max          48.000000\n",
       "Name: text_a, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本长度统计分析,通过分析可以看出文本较短，最长为48\r\n",
    "total['text_a'].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    83599.000000\n",
       "mean        19.815022\n",
       "std          3.883845\n",
       "min          3.000000\n",
       "25%         17.000000\n",
       "50%         20.000000\n",
       "75%         23.000000\n",
       "max         84.000000\n",
       "Name: text_a, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对测试集的长度统计分析，可以看出在长度上分布与训练数据相近\r\n",
    "test['text_a'].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存处理后的数据集文件\r\n",
    "train.to_csv('train.csv', sep='\\t', index=False)  # 保存训练集，格式为text_a,label\r\n",
    "dev.to_csv('dev.csv', sep='\\t', index=False)      # 保存验证集，格式为text_a,label\r\n",
    "test.to_csv('test.csv', sep='\\t', index=False)    # 保存测试集，格式为text_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三.基于PaddleNLP构建基线模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/75742955d912447c948bb679994a09039af5f85cfb554715be56c970db5ec3f6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.1 前置环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入所需的第三方库\r\n",
    "import math\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import collections\r\n",
    "from functools import partial\r\n",
    "import random\r\n",
    "import time\r\n",
    "import inspect\r\n",
    "import importlib\r\n",
    "from tqdm import tqdm\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle.io import IterableDataset\r\n",
    "from paddle.utils.download import get_path_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/da/77/364cd13f3488bc22297f5e07be2a1faf04f939844a3ea3fd84e3ab79489f/paddlenlp-2.1.1-py3-none-any.whl (735kB)\n",
      "\u001b[K     |████████████████████████████████| 737kB 10.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Collecting paddlefsl==1.0.0 (from paddlenlp)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/65/9970dd09309eb673303206befc9f2fdc9c2d29d31f002ae8d6c7b442f562/paddlefsl-1.0.0-py3-none-any.whl (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.5MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Collecting requests~=2.24.0 (from paddlefsl==1.0.0->paddlenlp)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 2.4MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pillow==8.2.0 (from paddlefsl==1.0.0->paddlenlp)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/33/34/542152297dcc6c47a9dcb0685eac6d652d878ed3cea83bf2b23cb988e857/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm~=4.27.0 (from paddlefsl==1.0.0->paddlenlp)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/16/33/6d8bd6a7c4238f383426b7593bf05bfd6d9e1f10c3084b56c0f14d973754/tqdm-4.27.0-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 230kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: paddlefsl 1.0.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: requests, pillow, tqdm, paddlefsl, paddlenlp\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: Pillow 7.1.2\n",
      "    Uninstalling Pillow-7.1.2:\n",
      "      Successfully uninstalled Pillow-7.1.2\n",
      "  Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "  Found existing installation: paddlenlp 2.0.7\n",
      "    Uninstalling paddlenlp-2.0.7:\n",
      "      Successfully uninstalled paddlenlp-2.0.7\n",
      "Successfully installed paddlefsl-1.0.0 paddlenlp-2.1.1 pillow-8.2.0 requests-2.24.0 tqdm-4.27.0\n"
     ]
    }
   ],
   "source": [
    "# 下载最新版本的paddlenlp\r\n",
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入paddlenlp所需的相关包\r\n",
    "import paddlenlp as ppnlp\r\n",
    "from paddlenlp.data import JiebaTokenizer, Pad, Stack, Tuple, Vocab\r\n",
    "from paddlenlp.datasets import MapDataset\r\n",
    "from paddle.dataset.common import md5file\r\n",
    "from paddlenlp.datasets import DatasetBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 定义要进行微调的预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-02 15:34:42,292] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/roberta_chn_large.pdparams\n",
      "[2021-11-02 15:34:47,107] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# 此次使用在中文领域效果较优的roberta-wwm-ext-large模型，预训练模型一般“大力出奇迹”，选用大的预训练模型可以取得比base模型更优的效果\r\n",
    "MODEL_NAME = \"roberta-wwm-ext-large\"\r\n",
    "# 只需指定想要使用的模型名称和文本分类的类别数即可完成Fine-tune网络定义，通过在预训练模型后拼接上一个全连接网络（Full Connected）进行分类\r\n",
    "model = ppnlp.transformers.RobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=14) # 此次分类任务为14分类任务，故num_classes设置为14\r\n",
    "# 定义模型对应的tokenizer，tokenizer可以把原始输入文本转化成模型model可接受的输入数据格式。需注意tokenizer类要与选择的模型相对应，具体可以查看PaddleNLP相关文档\r\n",
    "tokenizer = ppnlp.transformers.RobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 数据读取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['科技', '体育', '时政', '股票', '娱乐', '教育', '家居', '财经', '房产', '社会', '游戏', '彩票', '星座', '时尚']\n"
     ]
    }
   ],
   "source": [
    "# 定义要进行分类的14个类别\r\n",
    "label_list=list(train.label.unique())\r\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义数据集对应文件及其文件存储格式\r\n",
    "class NewsData(DatasetBuilder):\r\n",
    "    SPLITS = {\r\n",
    "        'train': 'train.csv',  # 训练集\r\n",
    "        'dev': 'dev.csv',      # 验证集\r\n",
    "    }\r\n",
    "\r\n",
    "    def _get_data(self, mode, **kwargs):\r\n",
    "        filename = self.SPLITS[mode]\r\n",
    "        return filename\r\n",
    "\r\n",
    "    def _read(self, filename):\r\n",
    "        \"\"\"读取数据\"\"\"\r\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\r\n",
    "            head = None\r\n",
    "            for line in f:\r\n",
    "                data = line.strip().split(\"\\t\")    # 以'\\t'分隔各列\r\n",
    "                if not head:\r\n",
    "                    head = data\r\n",
    "                else:\r\n",
    "                    text_a, label = data\r\n",
    "                    yield {\"text_a\": text_a, \"label\": label}  # 此次设置数据的格式为：text_a,label，可以根据具体情况进行修改\r\n",
    "\r\n",
    "    def get_labels(self):\r\n",
    "        return label_list   # 类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义数据集加载函数\r\n",
    "def load_dataset(name=None,\r\n",
    "                 data_files=None,\r\n",
    "                 splits=None,\r\n",
    "                 lazy=None,\r\n",
    "                 **kwargs):\r\n",
    "   \r\n",
    "    reader_cls = NewsData  # 加载定义的数据集格式\r\n",
    "    print(reader_cls)\r\n",
    "    if not name:\r\n",
    "        reader_instance = reader_cls(lazy=lazy, **kwargs)\r\n",
    "    else:\r\n",
    "        reader_instance = reader_cls(lazy=lazy, name=name, **kwargs)\r\n",
    "\r\n",
    "    datasets = reader_instance.read_datasets(data_files=data_files, splits=splits)\r\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.NewsData'>\n"
     ]
    }
   ],
   "source": [
    "# 加载训练和验证集\r\n",
    "train_ds, dev_ds = load_dataset(splits=[\"train\", \"dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义数据加载和处理函数\r\n",
    "def convert_example(example, tokenizer, max_seq_length=128, is_test=False):\r\n",
    "    qtconcat = example[\"text_a\"]\r\n",
    "    encoded_inputs = tokenizer(text=qtconcat, max_seq_len=max_seq_length)  # tokenizer处理为模型可接受的格式 \r\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\r\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\r\n",
    "\r\n",
    "    if not is_test:\r\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\r\n",
    "        return input_ids, token_type_ids, label\r\n",
    "    else:\r\n",
    "        return input_ids, token_type_ids\r\n",
    "\r\n",
    "# 定义数据加载函数dataloader\r\n",
    "def create_dataloader(dataset,\r\n",
    "                      mode='train',\r\n",
    "                      batch_size=1,\r\n",
    "                      batchify_fn=None,\r\n",
    "                      trans_fn=None):\r\n",
    "    if trans_fn:\r\n",
    "        dataset = dataset.map(trans_fn)\r\n",
    "\r\n",
    "    shuffle = True if mode == 'train' else False\r\n",
    "    # 训练数据集随机打乱，测试数据集不打乱\r\n",
    "    if mode == 'train':\r\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\r\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\r\n",
    "    else:\r\n",
    "        batch_sampler = paddle.io.BatchSampler(\r\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\r\n",
    "\r\n",
    "    return paddle.io.DataLoader(\r\n",
    "        dataset=dataset,\r\n",
    "        batch_sampler=batch_sampler,\r\n",
    "        collate_fn=batchify_fn,\r\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 参数设置：\r\n",
    "# 批处理大小，显存如若不足的话可以适当改小该值  \r\n",
    "batch_size = 300\r\n",
    "# 文本序列最大截断长度，需要根据文本具体长度进行确定，最长不超过512。 通过文本长度分析可以看出文本长度最大为48，故此处设置为48\r\n",
    "max_seq_length = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将数据处理成模型可读入的数据格式\r\n",
    "trans_func = partial(\r\n",
    "    convert_example,\r\n",
    "    tokenizer=tokenizer,\r\n",
    "    max_seq_length=max_seq_length)\r\n",
    "\r\n",
    "batchify_fn = lambda samples, fn=Tuple(\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\r\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\r\n",
    "    Stack()  # labels\r\n",
    "): [data for data in fn(samples)]\r\n",
    "\r\n",
    "# 训练集迭代器\r\n",
    "train_data_loader = create_dataloader(\r\n",
    "    train_ds,\r\n",
    "    mode='train',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn,\r\n",
    "    trans_fn=trans_func)\r\n",
    "\r\n",
    "# 验证集迭代器\r\n",
    "dev_data_loader = create_dataloader(\r\n",
    "    dev_ds,\r\n",
    "    mode='dev',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn,\r\n",
    "    trans_fn=trans_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.4 设置Fine-Tune优化策略，接入评价指标\n",
    "\n",
    "适用于BERT这类Transformer模型的学习率为warmup的动态学习率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/96164785831147b382bfc8d54161ec8794571c1528b34fa4b126e6d3d109be3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义超参，loss，优化器等\r\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\r\n",
    "\r\n",
    "# 定义训练配置参数：\r\n",
    "# 定义训练过程中的最大学习率\r\n",
    "learning_rate = 4e-5\r\n",
    "# 训练轮次\r\n",
    "epochs = 4\r\n",
    "# 学习率预热比例\r\n",
    "warmup_proportion = 0.1\r\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\r\n",
    "weight_decay = 0.01\r\n",
    "\r\n",
    "num_training_steps = len(train_data_loader) * epochs\r\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\r\n",
    "\r\n",
    "# AdamW优化器\r\n",
    "optimizer = paddle.optimizer.AdamW(\r\n",
    "    learning_rate=lr_scheduler,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=weight_decay,\r\n",
    "    apply_decay_param_fun=lambda x: x in [\r\n",
    "        p.name for n, p in model.named_parameters()\r\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\r\n",
    "    ])\r\n",
    "\r\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()  # 交叉熵损失函数\r\n",
    "metric = paddle.metric.Accuracy()              # accuracy评价指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.5 模型训练与评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ps：模型训练时，可以通过在终端输入nvidia-smi命令或者通过点击底部‘性能监控’选项查看显存的占用情况，适当调整好batchsize，防止出现显存不足意外暂停的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义模型训练验证评估函数\r\n",
    "@paddle.no_grad()\r\n",
    "def evaluate(model, criterion, metric, data_loader):\r\n",
    "    model.eval()\r\n",
    "    metric.reset()\r\n",
    "    losses = []\r\n",
    "    for batch in data_loader:\r\n",
    "        input_ids, token_type_ids, labels = batch\r\n",
    "        logits = model(input_ids, token_type_ids)\r\n",
    "        loss = criterion(logits, labels)\r\n",
    "        losses.append(loss.numpy())\r\n",
    "        correct = metric.compute(logits, labels)\r\n",
    "        metric.update(correct)\r\n",
    "        accu = metric.accumulate()\r\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))  # 输出验证集上评估效果\r\n",
    "    model.train()\r\n",
    "    metric.reset()\r\n",
    "    return accu  # 返回准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paddle.fluid.core_avx.Generator at 0x7f8fa0a55e70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 固定随机种子便于结果的复现\r\n",
    "seed = 1024\r\n",
    "random.seed(seed)\r\n",
    "np.random.seed(seed)\r\n",
    "paddle.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ps:模型训练时可以通过在终端输入nvidia-smi命令或通过底部右下的性能监控选项查看显存占用情况，显存不足的话要适当调整好batchsize的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995825\r"
     ]
    }
   ],
   "source": [
    "# 模型训练：\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "save_dir = \"checkpoint\"\r\n",
    "if not  os.path.exists(save_dir):\r\n",
    "    os.makedirs(save_dir)\r\n",
    "\r\n",
    "pre_accu=0\r\n",
    "accu=0\r\n",
    "global_step = 0\r\n",
    "for epoch in range(1, epochs + 1):\r\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\r\n",
    "        input_ids, segment_ids, labels = batch\r\n",
    "        logits = model(input_ids, segment_ids)\r\n",
    "        loss = criterion(logits, labels)\r\n",
    "        probs = F.softmax(logits, axis=1)\r\n",
    "        correct = metric.compute(probs, labels)\r\n",
    "        metric.update(correct)\r\n",
    "        acc = metric.accumulate()\r\n",
    "\r\n",
    "        global_step += 1\r\n",
    "        if global_step % 10 == 0 :\r\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        lr_scheduler.step()\r\n",
    "        optimizer.clear_grad()\r\n",
    "    # 每轮结束对验证集进行评估\r\n",
    "    accu = evaluate(model, criterion, metric, dev_data_loader)\r\n",
    "    print(accu)\r\n",
    "    if accu > pre_accu:\r\n",
    "        # 保存较上一轮效果更优的模型参数\r\n",
    "        save_param_path = os.path.join(save_dir, 'model_state.pdparams')  # 保存模型参数\r\n",
    "        paddle.save(model.state_dict(), save_param_path)\r\n",
    "        pre_accu=accu\r\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parameters from checkpoint/model_state.pdparams\n"
     ]
    }
   ],
   "source": [
    "# 加载在验证集上效果最优的一轮的模型参数\r\n",
    "import os\r\n",
    "import paddle\r\n",
    "\r\n",
    "params_path = 'checkpoint/model_state.pdparams'\r\n",
    "if params_path and os.path.isfile(params_path):\r\n",
    "    # 加载模型参数\r\n",
    "    state_dict = paddle.load(params_path)\r\n",
    "    model.set_dict(state_dict)\r\n",
    "    print(\"Loaded parameters from %s\" % params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.01377, accu: 0.99582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.995825"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试最优模型参数在验证集上的分数\r\n",
    "evaluate(model, criterion, metric, dev_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.6 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义模型预测函数\r\n",
    "def predict(model, data, tokenizer, label_map, batch_size=1):\r\n",
    "    examples = []\r\n",
    "    # 将输入数据（list格式）处理为模型可接受的格式\r\n",
    "    for text in data:\r\n",
    "        input_ids, segment_ids = convert_example(\r\n",
    "            text,\r\n",
    "            tokenizer,\r\n",
    "            max_seq_length=128,\r\n",
    "            is_test=True)\r\n",
    "        examples.append((input_ids, segment_ids))\r\n",
    "\r\n",
    "    batchify_fn = lambda samples, fn=Tuple(\r\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\r\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\r\n",
    "    ): fn(samples)\r\n",
    "\r\n",
    "    # Seperates data into some batches.\r\n",
    "    batches = []\r\n",
    "    one_batch = []\r\n",
    "    for example in examples:\r\n",
    "        one_batch.append(example)\r\n",
    "        if len(one_batch) == batch_size:\r\n",
    "            batches.append(one_batch)\r\n",
    "            one_batch = []\r\n",
    "    if one_batch:\r\n",
    "        # The last batch whose size is less than the config batch_size setting.\r\n",
    "        batches.append(one_batch)\r\n",
    "\r\n",
    "    results = []\r\n",
    "    model.eval()\r\n",
    "    for batch in batches:\r\n",
    "        input_ids, segment_ids = batchify_fn(batch)\r\n",
    "        input_ids = paddle.to_tensor(input_ids)\r\n",
    "        segment_ids = paddle.to_tensor(segment_ids)\r\n",
    "        logits = model(input_ids, segment_ids)\r\n",
    "        probs = F.softmax(logits, axis=1)\r\n",
    "        idx = paddle.argmax(probs, axis=1).numpy()\r\n",
    "        idx = idx.tolist()\r\n",
    "        labels = [label_map[i] for i in idx]\r\n",
    "        results.extend(labels)\r\n",
    "    return results  # 返回预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '科技', 1: '体育', 2: '时政', 3: '股票', 4: '娱乐', 5: '教育', 6: '家居', 7: '财经', 8: '房产', 9: '社会', 10: '游戏', 11: '彩票', 12: '星座', 13: '时尚'}\n"
     ]
    }
   ],
   "source": [
    "# 定义要进行分类的类别\r\n",
    "label_list=list(train.label.unique())\r\n",
    "label_map = { \r\n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\r\n",
    "}\r\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取要进行预测的测试集文件\r\n",
    "test = pd.read_csv('./test.csv',sep='\\t')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义对数据的预处理函数,处理为模型输入指定list格式\r\n",
    "def preprocess_prediction_data(data):\r\n",
    "    examples = []\r\n",
    "    for text_a in data:\r\n",
    "        examples.append({\"text_a\": text_a})\r\n",
    "    return examples\r\n",
    "\r\n",
    "# 对测试集数据进行格式处理\r\n",
    "data1 = list(test.text_a)\r\n",
    "examples = preprocess_prediction_data(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对测试集进行预测\r\n",
    "results = predict(model, examples, tokenizer, label_map, batch_size=16)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将list格式的预测结果存储为txt文件，提交格式要求：每行一个类别\r\n",
    "def write_results(labels, file_path):\r\n",
    "    with open(file_path, \"w\", encoding=\"utf8\") as f:\r\n",
    "        f.writelines(\"\\n\".join(labels))\r\n",
    "\r\n",
    "write_results(results, \"./result.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result.txt (deflated 89%)\n"
     ]
    }
   ],
   "source": [
    "# 因格式要求为zip，故需要将结果文件压缩为submission.zip提交文件\r\n",
    "!zip 'submission.zip' 'result.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 移动data目录下提交结果文件至主目录下，便于结果文件的保存\r\n",
    "!cp -r /home/aistudio/data/data103654/submission.zip /home/aistudio/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "需注意此次要求提交格式为zip，在主目录下找到生成的**submission.zip**文件下载到本地并到比赛页面进行提交即可！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/b4be47a31dca456688cb4a844bb0a4d2db0edb96e79c48d69679ffa2d50fa15f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四.提升方向：\n",
    "\n",
    "1.可以针对训练数据进行数据增强从而增大训练数据量以提升模型泛化能力。[NLP Chinese Data Augmentation 一键中文数据增强工具](https://github.com/425776024/nlpcda/)\n",
    "\n",
    "2.可以在基线模型的基础上通过调参及模型优化进一步提升效果。[文本分类上分微调技巧实战](https://mp.weixin.qq.com/s/CDIeTz6ETpdQEzjdeBW93g)\n",
    "\n",
    "3.可以尝试使用不同的预训练模型如ERNIE和NEZHA等，并对多模型的结果进行投票融合。[竞赛上分Trick-结果融合](https://aistudio.baidu.com/aistudio/projectdetail/2315563)\n",
    "\n",
    "4.可以将训练和验证集进行拼接后自定义训练和验证集的划分构建差异性结果用于融合或尝试5folds交叉验证等。\n",
    "\n",
    "5.取多模型预测结果中相同的部分作为伪标签用于模型的训练。伪标签技巧一般用于模型精度较高时，初学者慎用。\n",
    "\n",
    "6.有能力的可以尝试在训练语料下重新预训练以及修改模型网络结构等进一步提升效果。\n",
    "\n",
    "7.更多的技巧可以通过学习其他类似短文本分类比赛的Top分享，多做尝试。[零基础入门NLP - 新闻文本分类](https://tianchi.aliyun.com/competition/entrance/531810/forum)\n",
    "\n",
    "关于PaddleNLP的使用：建议多看官方最新文档 [PaddleNLP文档](https://paddlenlp.readthedocs.io/zh/latest/get_started/quick_start.html)\n",
    "\n",
    "PaddleNLP的github地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) 有问题的话可以在github上提issue，会有专人回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/1b8ebed473624c0e9781b26b1eda5ef16f4452d74c084ec48e12c2def21374e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五.个人介绍\n",
    "> 昵称：[炼丹师233](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406)\n",
    "\n",
    "> 目前主要方向：搞开发，主攻NLP和数据挖掘相关比赛或项目\n",
    "\n",
    "> [https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406) 关注我，下次带来更多精彩项目分享！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/2673cdd95c3c4ab78d0139bf53655259dfb55598841d43ad983fc1c7b2e1ebd7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
